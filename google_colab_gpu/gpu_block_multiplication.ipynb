{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deec1cc9",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Installation\n",
    "\n",
    "Install required packages and check GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CuPy for GPU computing (choose based on CUDA version)\n",
    "# For Colab (usually CUDA 11.x or 12.x):\n",
    "!pip install cupy-cuda11x -q\n",
    "\n",
    "# If above fails, try:\n",
    "# !pip install cupy-cuda12x -q\n",
    "\n",
    "print(\"‚úì Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1916f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from scipy import sparse as sp\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"GPU Available:\", cp.cuda.is_available())\n",
    "if cp.cuda.is_available():\n",
    "    device = cp.cuda.Device()\n",
    "    print(f\"GPU Device: {device}\")\n",
    "    print(f\"GPU Memory: {device.mem_info[1] / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Make sure Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732ac18",
   "metadata": {},
   "source": [
    "## Step 2: Upload Data Files\n",
    "\n",
    "Upload your sparse matrix CSV files (matrix_a.csv, matrix_b.csv) from the `data/input` folder.\n",
    "\n",
    "**Format**: Each line should be: `row,col,value` (1-based indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8153ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload matrix_a.csv and matrix_b.csv\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(\"\\n‚úì Files uploaded:\")\n",
    "for filename in uploaded.keys():\n",
    "    size_mb = len(uploaded[filename]) / 1e6\n",
    "    print(f\"  - {filename}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324424b",
   "metadata": {},
   "source": [
    "## Step 3: Define Block Multiplication Class\n",
    "\n",
    "Core implementation of block-based multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockMatrixMultiplier:\n",
    "    \"\"\"\n",
    "    Block-based matrix multiplication for large matrices on GPU.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gpu_memory_gb=12, safety_factor=0.7):\n",
    "        \"\"\"\n",
    "        Initialize block multiplier.\n",
    "        \n",
    "        Args:\n",
    "            gpu_memory_gb: Available GPU memory in GB\n",
    "            safety_factor: Use only 70% of memory to be safe\n",
    "        \"\"\"\n",
    "        self.gpu_memory_bytes = int(gpu_memory_gb * 1e9 * safety_factor)\n",
    "        self.gpu_available = cp.cuda.is_available()\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            device = cp.cuda.Device()\n",
    "            actual_memory = device.mem_info[1] / 1e9\n",
    "            print(f\"‚úì GPU Available: {device}\")\n",
    "            print(f\"‚úì Total GPU Memory: {actual_memory:.1f}GB\")\n",
    "            print(f\"‚úì Using: {gpu_memory_gb * safety_factor:.1f}GB ({safety_factor*100:.0f}%)\")\n",
    "        else:\n",
    "            raise RuntimeError(\"No GPU available!\")\n",
    "    \n",
    "    def estimate_block_size(self, matrix_size, sparsity=0.99):\n",
    "        \"\"\"\n",
    "        Estimate optimal block size based on available GPU memory.\n",
    "        \"\"\"\n",
    "        # Conservative estimate\n",
    "        bytes_per_element = 8  # float32 + overhead\n",
    "        max_elements = self.gpu_memory_bytes // bytes_per_element\n",
    "        \n",
    "        # block_size √ó matrix_size √ó 2 (A block + B block)\n",
    "        block_size = int(max_elements / (2 * matrix_size))\n",
    "        \n",
    "        # Clamp to reasonable range\n",
    "        block_size = min(block_size, matrix_size, 5000)\n",
    "        block_size = max(block_size, 100)\n",
    "        \n",
    "        num_blocks = int(np.ceil(matrix_size / block_size))\n",
    "        memory_per_block_gb = block_size * matrix_size * 4 * 2 / 1e9\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Memory Estimation:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Matrix size: {matrix_size:,} √ó {matrix_size:,}\")\n",
    "        print(f\"Block size: {block_size:,} √ó {block_size:,}\")\n",
    "        print(f\"Number of blocks: {num_blocks} √ó {num_blocks} = {num_blocks**2}\")\n",
    "        print(f\"Memory per block: ~{memory_per_block_gb:.2f}GB\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        return block_size\n",
    "    \n",
    "    def load_sparse_csv(self, filepath, matrix_size):\n",
    "        \"\"\"\n",
    "        Load sparse matrix from CSV file.\n",
    "        \"\"\"\n",
    "        print(f\"Loading: {filepath}...\")\n",
    "        \n",
    "        rows, cols, vals = [], [], []\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for parts in reader:\n",
    "                if len(parts) == 3:\n",
    "                    try:\n",
    "                        # Convert 1-based to 0-based indexing\n",
    "                        r = int(parts[0]) - 1\n",
    "                        c = int(parts[1]) - 1\n",
    "                        v = float(parts[2])\n",
    "                        \n",
    "                        if 0 <= r < matrix_size and 0 <= c < matrix_size:\n",
    "                            rows.append(r)\n",
    "                            cols.append(c)\n",
    "                            vals.append(v)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        nnz = len(vals)\n",
    "        sparsity = 100 * (1 - nnz / (matrix_size * matrix_size))\n",
    "        \n",
    "        print(f\"  ‚úì {nnz:,} non-zero entries\")\n",
    "        print(f\"  ‚úì {sparsity:.4f}% sparse\\n\")\n",
    "        \n",
    "        # Create CSR matrix\n",
    "        sparse_mat = sp.csr_matrix((vals, (rows, cols)), \n",
    "                                   shape=(matrix_size, matrix_size))\n",
    "        \n",
    "        return sparse_mat\n",
    "    \n",
    "    def multiply_sparse_block(self, A_csr, B_csr, row_start, row_end, \n",
    "                               col_start, col_end):\n",
    "        \"\"\"\n",
    "        Multiply a block of A with a block of B on GPU.\n",
    "        \"\"\"\n",
    "        # Extract blocks\n",
    "        A_block = A_csr[row_start:row_end, :].toarray()\n",
    "        B_block = B_csr[:, col_start:col_end].toarray()\n",
    "        \n",
    "        # Transfer to GPU\n",
    "        A_gpu = cp.asarray(A_block, dtype=cp.float32)\n",
    "        B_gpu = cp.asarray(B_block, dtype=cp.float32)\n",
    "        \n",
    "        # Multiply on GPU\n",
    "        C_gpu = cp.matmul(A_gpu, B_gpu)\n",
    "        \n",
    "        # Transfer back to CPU\n",
    "        C_block = cp.asnumpy(C_gpu)\n",
    "        \n",
    "        # Clean up GPU memory\n",
    "        del A_gpu, B_gpu, C_gpu\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "        return C_block\n",
    "    \n",
    "    def multiply_blocks(self, A_csr, B_csr, block_size, output_dir=\"./blocks\"):\n",
    "        \"\"\"\n",
    "        Multiply two matrices using block algorithm.\n",
    "        \"\"\"\n",
    "        matrix_size = A_csr.shape[0]\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Calculate blocks\n",
    "        num_blocks = int(np.ceil(matrix_size / block_size))\n",
    "        total_blocks = num_blocks * num_blocks\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting Block Multiplication\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total blocks: {num_blocks} √ó {num_blocks} = {total_blocks}\")\n",
    "        print(f\"Output: {output_dir}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        metadata = {\n",
    "            'matrix_size': matrix_size,\n",
    "            'block_size': block_size,\n",
    "            'num_blocks': num_blocks,\n",
    "            'blocks': []\n",
    "        }\n",
    "        \n",
    "        total_time = 0\n",
    "        block_count = 0\n",
    "        \n",
    "        # Process each block\n",
    "        for i in range(num_blocks):\n",
    "            row_start = i * block_size\n",
    "            row_end = min(row_start + block_size, matrix_size)\n",
    "            \n",
    "            for j in range(num_blocks):\n",
    "                col_start = j * block_size\n",
    "                col_end = min(col_start + block_size, matrix_size)\n",
    "                \n",
    "                block_count += 1\n",
    "                \n",
    "                print(f\"[{block_count}/{total_blocks}] Block ({i},{j}): \"\n",
    "                      f\"rows [{row_start}:{row_end}], cols [{col_start}:{col_end}]\", \n",
    "                      end=\" \")\n",
    "                \n",
    "                # Multiply\n",
    "                start = time.perf_counter()\n",
    "                C_block = self.multiply_sparse_block(\n",
    "                    A_csr, B_csr, row_start, row_end, col_start, col_end\n",
    "                )\n",
    "                elapsed = time.perf_counter() - start\n",
    "                total_time += elapsed\n",
    "                \n",
    "                # Save\n",
    "                filename = f\"block_{i}_{j}.npy\"\n",
    "                np.save(os.path.join(output_dir, filename), C_block)\n",
    "                \n",
    "                nnz = np.count_nonzero(C_block)\n",
    "                print(f\"‚Üí {nnz:,} nnz, {elapsed:.3f}s ‚úì\")\n",
    "                \n",
    "                metadata['blocks'].append({\n",
    "                    'i': i, 'j': j,\n",
    "                    'row_start': row_start, 'row_end': row_end,\n",
    "                    'col_start': col_start, 'col_end': col_end,\n",
    "                    'filename': filename,\n",
    "                    'time': elapsed\n",
    "                })\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_path = os.path.join(output_dir, 'metadata.json')\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚úì Complete! Total: {total_time:.2f}s, Avg: {total_time/total_blocks:.3f}s/block\")\n",
    "        print(f\"‚úì Metadata: {metadata_path}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        return metadata_path\n",
    "    \n",
    "    def reconstruct_result(self, metadata_path):\n",
    "        \"\"\"\n",
    "        Reconstruct full result matrix from blocks.\n",
    "        \"\"\"\n",
    "        print(\"\\nReconstructing result matrix...\")\n",
    "        \n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        matrix_size = metadata['matrix_size']\n",
    "        output_dir = os.path.dirname(metadata_path)\n",
    "        \n",
    "        # Collect sparse entries\n",
    "        rows, cols, vals = [], [], []\n",
    "        \n",
    "        for block_info in metadata['blocks']:\n",
    "            block_path = os.path.join(output_dir, block_info['filename'])\n",
    "            C_block = np.load(block_path)\n",
    "            \n",
    "            row_start = block_info['row_start']\n",
    "            col_start = block_info['col_start']\n",
    "            \n",
    "            # Extract non-zeros\n",
    "            block_rows, block_cols = np.nonzero(C_block)\n",
    "            for r, c in zip(block_rows, block_cols):\n",
    "                rows.append(row_start + r)\n",
    "                cols.append(col_start + c)\n",
    "                vals.append(C_block[r, c])\n",
    "        \n",
    "        result_csr = sp.csr_matrix((vals, (rows, cols)), \n",
    "                                   shape=(matrix_size, matrix_size))\n",
    "        \n",
    "        nnz = result_csr.nnz\n",
    "        sparsity = 100 * (1 - nnz / matrix_size**2)\n",
    "        \n",
    "        print(f\"‚úì Result: {nnz:,} non-zeros, {sparsity:.4f}% sparse\\n\")\n",
    "        \n",
    "        return result_csr\n",
    "\n",
    "print(\"‚úì BlockMatrixMultiplier class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc320e49",
   "metadata": {},
   "source": [
    "## Step 4: Configure and Run Block Multiplication\n",
    "\n",
    "Set parameters and execute the multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c21c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MATRIX_SIZE = 50000  # Adjust based on your data\n",
    "GPU_MEMORY_GB = 12   # Google Colab typically has 12-15GB\n",
    "\n",
    "# File paths\n",
    "MATRIX_A_FILE = \"matrix_a.csv\"\n",
    "MATRIX_B_FILE = \"matrix_b.csv\"\n",
    "OUTPUT_DIR = \"./block_results\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Matrix size: {MATRIX_SIZE:,} √ó {MATRIX_SIZE:,}\")\n",
    "print(f\"  GPU memory: {GPU_MEMORY_GB}GB\")\n",
    "print(f\"  Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multiplier\n",
    "multiplier = BlockMatrixMultiplier(gpu_memory_gb=GPU_MEMORY_GB)\n",
    "\n",
    "# Estimate optimal block size\n",
    "block_size = multiplier.estimate_block_size(MATRIX_SIZE, sparsity=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a25f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matrices\n",
    "print(\"Loading matrices...\\n\")\n",
    "A_csr = multiplier.load_sparse_csv(MATRIX_A_FILE, MATRIX_SIZE)\n",
    "B_csr = multiplier.load_sparse_csv(MATRIX_B_FILE, MATRIX_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply using blocks (this will take some time!)\n",
    "metadata_path = multiplier.multiply_blocks(A_csr, B_csr, block_size, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b670bfe",
   "metadata": {},
   "source": [
    "## Step 5: Reconstruct and Save Result\n",
    "\n",
    "Combine all blocks into the final result matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b51731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct result\n",
    "result_csr = multiplier.reconstruct_result(metadata_path)\n",
    "\n",
    "# Save result\n",
    "result_file = os.path.join(OUTPUT_DIR, \"result_matrix.npz\")\n",
    "sp.save_npz(result_file, result_csr)\n",
    "\n",
    "print(f\"\\n‚úì Final result saved: {result_file}\")\n",
    "print(f\"  Shape: {result_csr.shape}\")\n",
    "print(f\"  Non-zeros: {result_csr.nnz:,}\")\n",
    "print(f\"  File size: {os.path.getsize(result_file) / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e28909",
   "metadata": {},
   "source": [
    "## Step 6: Download Results\n",
    "\n",
    "Download the result files to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a876db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download result matrix\n",
    "files.download(result_file)\n",
    "\n",
    "# Download metadata (for reference)\n",
    "files.download(metadata_path)\n",
    "\n",
    "print(\"\\n‚úì Files ready for download!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd74ab3",
   "metadata": {},
   "source": [
    "## Optional: Verification\n",
    "\n",
    "Compare a small sample with CPU computation to verify correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffae5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify with small sample\n",
    "print(\"Verification: Computing small sample on CPU...\\n\")\n",
    "\n",
    "# Take first 100x100 block\n",
    "sample_size = 100\n",
    "A_sample = A_csr[:sample_size, :sample_size]\n",
    "B_sample = B_csr[:sample_size, :sample_size]\n",
    "result_sample = result_csr[:sample_size, :sample_size]\n",
    "\n",
    "# Compute on CPU\n",
    "expected = A_sample @ B_sample\n",
    "\n",
    "# Compare\n",
    "diff = np.abs(expected - result_sample).max()\n",
    "\n",
    "print(f\"Maximum difference: {diff}\")\n",
    "if diff < 1e-4:\n",
    "    print(\"‚úì Verification PASSED! Results match.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: Results differ slightly (may be due to floating point precision)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7004c49",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "‚úÖ **Loaded large sparse matrices** from CSV files  \n",
    "‚úÖ **Estimated optimal block size** based on GPU memory  \n",
    "‚úÖ **Multiplied matrices in chunks** that fit in GPU memory  \n",
    "‚úÖ **Saved intermediate results** to disk  \n",
    "‚úÖ **Reconstructed final result** from blocks  \n",
    "\n",
    "### Key Advantages:\n",
    "\n",
    "- üöÄ **Scalable**: Can handle matrices of ANY size\n",
    "- üíæ **Memory-efficient**: Only loads small chunks into GPU\n",
    "- ‚ö° **Fast**: Uses GPU for actual computation\n",
    "- üîÑ **Flexible**: Adjusts block size based on available memory\n",
    "\n",
    "### Comparison:\n",
    "\n",
    "| Method | Memory | Speed | Scalability |\n",
    "|--------|--------|-------|-------------|\n",
    "| **Dense CPU** | 80GB+ | Slow | ‚ùå Limited |\n",
    "| **Dense GPU (naive)** | 80GB+ | **CRASHES** | ‚ùå Fails |\n",
    "| **Block GPU (this)** | 12GB | Fast | ‚úÖ **Unlimited** |\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Adjust `MATRIX_SIZE` if your matrices are different\n",
    "2. Tune `block_size` for your specific GPU memory\n",
    "3. Save result in different formats (CSV, dense, etc.)\n",
    "4. Compare performance with CPU sparse multiplication"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
